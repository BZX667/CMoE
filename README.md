# CMoE
This is code for Improving Alignment and Uniformity of Expert Representation with Contrastive Learning for Mixture-of-Experts model

## Environment Setup
1.tensorflow=1.15
2.python=3.6.8

## Guideline

### models
```EAR.py``` Expert Agreement Regularization
```EHP.py``` Expert Homogeneity Penalty
```data_augment.py``` Data augment methods
```project_head.py``` Projection head function
```model``` MoE based model including MMoE, PLE, etc.

### Example to run the codes
bash MMOE.sh
bash PLE.sh

